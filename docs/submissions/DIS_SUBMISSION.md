# Conversational Cartography: Mapping Human–AI Interaction as Navigable Terrain

**DIS 2026 Submission Draft**
**Format:** Full Paper
**Theme:** Critical Design / Provocation

---

## Abstract

We present "Conversational Cartography," a critical design artifact that stages encounters with relational dynamics in human-AI conversation. Rather than treating conversation as a linear transcript, we encode it as movement through relational-affective space—where X-axis represents functional/social orientation, Y-axis measures aligned/divergent structure, and Z-axis encodes emotional intensity via the PAD (Pleasure-Arousal-Dominance) model. Analysis of 533 conversations (345 validated) from Chatbot Arena, OASST, and WildChat reveals how conversations move through the relational space we've constructed: interactions with identical role classifications take dramatically different affective journeys, with variance ratios up to 82x between calm information-seeking (variance 0.0004) and volatile adversarial testing (variance 0.0164). The visualization makes visible patterns of positioning, authority distribution, and emotional intensity that typically remain invisible. K-means clustering identifies 7 patterns that emerge from our encoding choices—not fixed archetypes, but continuous patterns (silhouette score 0.160) revealing how conversations move through relational space. We use GPT-5.2 to classify conversations using a 12-role Social Role Theory taxonomy, creating a methodological circularity that reveals how AI systems interpret their own interactions. When we encode conversations spatially, trajectory features account for 82.7% of cluster separation—revealing what our encoding privileges rather than what conversations "are." The visualization is not a diagnostic tool or optimization interface, but a critical artifact that provokes questions about what should—and should not—be made legible in AI-mediated relationships.

---

## 1. Contribution Statement

Our work makes three primary contributions to the field of Designing Interactive Systems:

1.  **Critical Design Contribution:** We stage encounters with relational dynamics that are typically invisible, making visible the assumptions and consequences of how we represent human-AI interaction. By shifting the metaphor from "log" to "terrain," we provoke new ways of seeing the emotional labor and power dynamics inherent in these exchanges.
2.  **Methodological Contribution:** We demonstrate how spatial encoding creates particular ways of seeing relational dynamics. We show that our design choices—privileging trajectory over content—reveal what becomes visible and what remains hidden, challenging the notion of neutral data representation.
3.  **Theoretical Contribution:** We connect conversation trajectories to Watzlawick's interactional framework, showing how relational positioning unfolds through specific interactional patterns like drift, escalation, and role inversion.

---

## 2. Methods: Staging the Encounter

Our methodology is not a neutral pipeline but a series of design choices that construct a specific way of seeing.

### Dataset & Bias as Feature
We analyzed 533 conversations (345 in our validated corpus), including 160 from Chatbot Arena/OASST (evaluation context) and 185 from WildChat (organic usage). The dataset is biased: 83.1% of Chatbot Arena interactions are "information-seeking." Rather than treating this as a limitation, we frame it as revealing: the visualization shows what relational dynamics look like in a context where users are testing models versus genuinely seeking help.

### Methodological Circularity
We use GPT-5.2 to classify interactions using a 12-role Social Role Theory taxonomy (e.g., *expert-system*, *relational-peer*, *adversarial-tester*). This creates a methodological circularity: the AI is both the object of study and the instrument of measurement. We acknowledge this as a design choice that stages a particular way of seeing—using AI's own interpretive framework to reveal patterns in AI-mediated interaction. The confidence scores (average 0.743) reflect the internal consistency of this machine gaze.

### Spatial Encoding
We constructed a 3D relational space to map these interactions:
*   **X-Axis (Function):** Functional (0.0) ↔ Social (1.0)
*   **Y-Axis (Structure):** Aligned (0.0) ↔ Divergent (1.0)
*   **Z-Axis (Intensity):** PAD Model (Pleasure-Arousal-Dominance), mapping emotional intensity from calm (0.0) to volatile/frustrated (1.0).

Path trajectories are generated by calculating "drift" based on linguistic features per message, visualizing conversation not as a static object but as a journey.

---

## 3. Findings: What the Terrain Reveals

When we encode conversations spatially, several patterns emerge from the terrain:

### 3.1. Same Destination, Different Journeys
Conversations with identical role classifications often take dramatically different paths. For example, two interactions classified as "information-seeker → expert-system" show an 82x difference in variance. One is a flat, detached browse (variance 0.0004); the other is a jagged, volatile adversarial test (variance 0.0164). The visualization makes visible the "relational work" (or lack thereof) that categorical labels obscure.

### 3.2. Patterns of Positioning (The "7 Clusters")
K-means clustering identifies 7 patterns in how conversations move through our constructed space. These are not universal "archetypes" but patterns emerging from our encoding.
*   **Finding:** 82.7% of cluster separation is driven by trajectory features (drift, straightness, intensity patterns).
*   **Interpretation:** This finding reveals that our encoding privileges relational dynamics over categorical content. It stages a question: What would we see if we privileged different features? The "82.7%" is a quantification of our design lens.

### 3.3. The "Paradox of Micro-Diversity"
Despite role homogeneity (most interactions are "functional"), we observe high path variance (60.3% monoculture in roles vs. high spatial diversity). This suggests that even within constrained functional roles, humans and AIs negotiate minute variations in positioning—micro-drifts in authority and alignment that the spatial encoding magnifies.

---

## 4. Discussion: Limitations as Design Choices

We position our limitations not as failures of rigour, but as revealing features of the design:

*   **Small Sample Size & "Archetypes":** Our smallest clusters contain only 6 conversations. These are not statistically validated archetypes but "boundary cases" that resist easy categorization. They reveal the limits of our encoding and point to where the model breaks down—often the most interesting sites for critical inquiry.
*   **The "Valley" Interpretation:** We interpret low-intensity "valleys" in the terrain as moments of affiliation or ease. However, they could also represent disengagement or boredom. This ambiguity is inherent to the visualization; it demands interpretation rather than providing objective truth.
*   **Reification Risks:** By visualizing "relational drift," we risk reifying fluid social dynamics into rigid spatial paths. We counter this by framing the visualization as a "staging of encounters"—a provoke to look, not a definitive map of territory.

---

## Conclusion

"Conversational Cartography" does not claim to show what human-AI conversation *is* in a universal sense. Instead, it shows what becomes visible when we choose to see interaction as movement through a relational-affective terrain. By making visible the hidden dynamics of drift, escalation, and positioning, the artifact invites us to question the flat, log-centric metaphors we currently use to understand our relationship with AI.
