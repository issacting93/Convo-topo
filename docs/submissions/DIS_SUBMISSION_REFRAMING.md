# DIS Submission Reframing: Critical Design vs. Empirical Claims

**Purpose:** Address methodological tensions and reframe submission as critical design rather than empirical research

---

## Core Tension Identified

**Current framing mixes:**
- Critical design language ("exploratory," "reflective," "staging encounters")
- Empirical claims ("7 relational positioning archetypes," "82.7% feature importance")

**Problem:** These are incompatible frames. Critical design provokes questions; empirical research answers them.

---

## Reframing Strategy

### From: Empirical Discovery
> "We identify 7 relational positioning archetypes through trajectory analysis. 82.7% of feature importance comes from trajectory characteristics."

### To: Critical Design Provocation
> "We stage encounters with relational dynamics that typically remain invisible. The visualization reveals how conversations move through relational space—not as fixed types, but as continuous patterns of positioning. The 82.7% finding is not a claim about conversations themselves, but about what becomes visible when we encode them spatially."

---

## Key Reframings

### 1. The "82.7% Finding"

**Current framing (empirical):**
> "82.7% of feature importance comes from trajectory characteristics. This directly supports our thesis that how conversations move through relational space matters more than what they're about."

**Reframed (critical design):**
> "When we encode conversations spatially, trajectory characteristics (drift, path straightness, emotional intensity patterns) account for 82.7% of what distinguishes one visualization from another. This is not a claim about conversations themselves, but about what the spatial encoding makes visible. The finding reveals that our encoding privileges relational dynamics over categorical content—a design choice that stages a particular way of seeing."

**Why this matters:**
- Acknowledges the encoding is interpretive, not neutral
- Frames the finding as revealing the design's assumptions
- Shifts from "what conversations are" to "what becomes visible"

---

### 2. The "7 Archetypes"

**Current framing (empirical):**
> "Analysis of 160 classified conversations reveals 7 distinct relational positioning archetypes in human-AI conversations."

**Reframed (critical design):**
> "The clustering algorithm identifies 7 patterns in how conversations move through the relational space we've constructed. These are not 'archetypes' in the sense of universal types, but patterns that emerge from our specific encoding choices: the 9-dimension taxonomy, the PAD model, the drift formula, the spatial mapping. The smallest clusters (3.8%, 6 conversations each) are suggestive rather than validated—they reveal what becomes visible when we apply this particular lens."

**Why this matters:**
- Acknowledges small sample size
- Frames clusters as artifacts of the encoding, not discoveries about conversations
- Maintains the provocation while avoiding overclaiming

---

### 3. Methodological Circularity (AI Classifying AI)

**Current framing (implicit):**
> Uses GPT-4o-mini to classify conversations, presents confidence scores as validation.

**Reframed (explicit acknowledgment):**
> "We use GPT-4o-mini to classify conversations using a taxonomy we designed. This creates a methodological circularity: the AI is both the object of study (human-AI conversation dynamics) and the instrument of measurement (classifier). We acknowledge this as a design choice that stages a particular way of seeing relational dynamics—one that uses AI's own interpretive framework to reveal patterns in AI-mediated interaction. The confidence scores (0.75-0.85) reflect internal consistency of the LLM's application of our prompt, not external validation. This circularity is not a bug but a feature: it reveals how AI systems interpret their own interactions."

**Why this matters:**
- Transforms weakness into critical insight
- Frames circularity as revealing AI's interpretive framework
- Aligns with critical design's interest in making assumptions visible

---

### 4. Dataset Bias

**Current framing (limitation):**
> "83.1% information-seeking reflects Chatbot Arena's evaluation context. This is a limitation."

**Reframed (design choice):**
> "Our dataset (160 conversations, 83.1% information-seeking) reflects Chatbot Arena's evaluation context. Rather than treating this as a limitation to overcome, we treat it as revealing: the visualization shows what relational dynamics look like in a context where users are testing models rather than genuinely seeking help. The bias becomes visible in the terrain—most conversations cluster in functional/structured patterns, suggesting that evaluation contexts produce particular relational configurations. This is not a flaw in the data but a feature of what becomes visible: the visualization stages encounters with how evaluation contexts shape relational positioning."

**Why this matters:**
- Reframes bias as revealing rather than limiting
- Connects to critical design's interest in making power relations visible
- Shows how the visualization reveals the context that produced the data

---

### 5. Small Sample Size

**Current framing (implicit):**
> Presents clusters as validated archetypes despite small samples.

**Reframed (explicit):**
> "The clustering identifies patterns across 160 conversations, with the smallest clusters containing 6 conversations each (3.8%). These are not validated archetypes but suggestive patterns that emerge from our encoding. The visualization's value is not in discovering universal types, but in staging encounters with relational dynamics that are typically invisible. The small clusters are particularly interesting as boundary cases—conversations that resist easy categorization, revealing the limits of our encoding."

**Why this matters:**
- Honest about sample size
- Frames small clusters as revealing boundary cases
- Shifts from validation to provocation

---

## Revised DIS Submission Structure

### Abstract (Revised)

**From:**
> "We present a visual framework for understanding human-AI conversation as movement through relational-affective space. Analysis of 160 conversations reveals 7 distinct relational positioning archetypes. 82.7% of feature importance comes from trajectory characteristics, supporting our thesis that how conversations move through relational space matters more than what they're about."

**To:**
> "We present a critical design artifact that stages encounters with relational dynamics in human-AI conversation. Rather than treating conversation as linear transcript, we encode it as movement through relational-affective space, making visible patterns of positioning, authority distribution, and emotional intensity that typically remain invisible. The visualization reveals how conversations move through the relational space we've constructed—not as fixed types, but as continuous patterns that emerge from our encoding choices. We use AI to classify AI-mediated interactions, creating a methodological circularity that reveals how AI systems interpret their own interactions. The visualization is not a diagnostic tool or optimization interface, but a critical artifact that provokes questions about what should—and should not—be made legible in AI-mediated relationships."

---

## Key Sections to Revise

### 1. Contribution Statement

**Current:**
- Methodological: Demonstrates how spatial representation reveals relational positioning
- Substantive: Identifies 7 systematic archetypes in human-AI conversation
- Theoretical: Connects conversation trajectories to Watzlawick's framework

**Revised:**
- **Critical Design Contribution:** Stages encounters with relational dynamics that are typically invisible, making visible the assumptions and consequences of how we represent human-AI interaction
- **Methodological Contribution:** Demonstrates how spatial encoding creates particular ways of seeing relational dynamics, revealing what becomes visible and what remains hidden
- **Theoretical Contribution:** Connects conversation trajectories to Watzlawick's framework, showing how relational positioning unfolds through interactional patterns

---

### 2. Findings Section

**Current language (empirical):**
- "We discovered..."
- "Analysis reveals..."
- "The data shows..."

**Revised language (critical design):**
- "The visualization makes visible..."
- "When we encode conversations spatially, we see..."
- "The clustering algorithm identifies patterns that emerge from our encoding choices..."
- "The terrain reveals..."

---

### 3. Limitations Section

**Current:**
- Lists limitations as weaknesses to address

**Revised:**
- Frames limitations as revealing design choices
- Methodological circularity → reveals AI's interpretive framework
- Dataset bias → reveals how evaluation contexts shape relational positioning
- Small sample → reveals boundary cases and encoding limits

---

## Addressing Specific Critiques

### Critique: "82.7% is about your features, not conversations"

**Response:**
> "Exactly. The 82.7% finding reveals what our spatial encoding privileges: trajectory characteristics over categorical content. This is not a claim about conversations themselves, but about what becomes visible when we encode them spatially. The finding stages a question: What would we see if we privileged different features? The visualization is not showing 'what conversations are' but 'what becomes visible when we look at them this way.'"

---

### Critique: "6 conversations is not an archetype"

**Response:**
> "Agreed. The smallest clusters (6 conversations, 3.8%) are not validated archetypes but suggestive patterns that emerge from our encoding. They're particularly interesting as boundary cases—conversations that resist easy categorization, revealing the limits of our spatial encoding. The visualization's value is not in discovering universal types, but in staging encounters with relational dynamics that are typically invisible."

---

### Critique: "No user validation"

**Response:**
> "As a critical design artifact, the visualization's value is not in user validation but in staging encounters with relational dynamics. User studies would be valuable for understanding how people interpret the visualization, but they're not required for a critical design contribution. The artifact's purpose is to provoke questions, not to answer them."

---

### Critique: "Methodological circularity"

**Response:**
> "The circularity is intentional. Using AI to classify AI-mediated interactions reveals how AI systems interpret their own interactions. This is not a methodological flaw but a critical design choice that makes visible the interpretive framework AI systems use. The visualization stages encounters with how AI sees itself."

---

## Revised Contribution Statement

**For DIS Abstract:**

> "We present a critical design artifact that stages encounters with relational dynamics in human-AI conversation. The visualization encodes conversation as movement through relational-affective space, making visible patterns of positioning, authority distribution, and emotional intensity that typically remain invisible in linear transcripts. We use AI to classify AI-mediated interactions, creating a methodological circularity that reveals how AI systems interpret their own interactions. The visualization is not a diagnostic tool or optimization interface, but a critical artifact that provokes questions about what should—and should not—be made legible in AI-mediated relationships. Through annotated visualizations of diverse conversations, we demonstrate how this approach surfaces insights about human-AI interaction without reducing it to psychological inference or fixed categories. The artifact challenges text-centric analysis, privileging visual representation as both method and medium for understanding relational dynamics."

---

## Key Language Shifts

| From (Empirical) | To (Critical Design) |
|------------------|----------------------|
| "We discovered..." | "The visualization makes visible..." |
| "Analysis reveals..." | "When we encode conversations spatially..." |
| "The data shows..." | "The terrain reveals..." |
| "7 archetypes" | "7 patterns that emerge from our encoding" |
| "82.7% proves..." | "82.7% reveals what our encoding privileges" |
| "Limitation" | "Design choice that reveals..." |
| "Validated" | "Suggestive" or "Revealing" |
| "We found..." | "The clustering algorithm identifies..." |

---

## Conclusion

The reframing shifts from **empirical discovery** to **critical design provocation**:

- **Not:** "We discovered 7 archetypes"
- **But:** "The visualization stages encounters with 7 patterns that emerge from our encoding"

- **Not:** "82.7% proves trajectory matters more"
- **But:** "82.7% reveals what our spatial encoding privileges"

- **Not:** "Methodological circularity is a limitation"
- **But:** "Circularity reveals how AI systems interpret their own interactions"

This reframing aligns the submission with critical design's goals: **staging encounters, provoking questions, making assumptions visible**—rather than making empirical claims about human-AI conversation patterns.

